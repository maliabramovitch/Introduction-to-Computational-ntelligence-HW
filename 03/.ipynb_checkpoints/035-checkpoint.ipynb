{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10171f1555ea728d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:16:29.586450Z",
     "start_time": "2025-02-17T11:16:29.569171Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import MixedVariableObjectiveFunctions as f_mixed\n",
    "from MixedVariableObjectiveFunctions import setC\n",
    "import ellipsoidFunctions as Efunc\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b172edbf04ed2b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:16:29.656705Z",
     "start_time": "2025-02-17T11:16:29.600794Z"
    }
   },
   "outputs": [],
   "source": [
    "def OnePlusOneEvolutionStrategy(n, lb, ub, maxEvals, func=lambda x: x.dot(x), fstop=0, seed=None, record_interval=50):\n",
    "    \"\"\"\n",
    "    (1+1)-Evolution Strategy with the 1/5th success-rule initialized within [lb,ub]^n.\n",
    "    \"\"\"\n",
    "    local_state = np.random.RandomState(seed)\n",
    "    fhistory, shistory = [], []\n",
    "    xmin = local_state.uniform(size=n) * (ub - lb) + lb\n",
    "    fmin = func(xmin.reshape(1, -1))\n",
    "    fmin = fmin.item() if hasattr(fmin, \"item\") else fmin\n",
    "    fhistory.append(fmin)\n",
    "    sigma = (ub - lb) / 6.0\n",
    "    shistory.append(sigma)\n",
    "    evalcount, osuccess = 0, 0\n",
    "    tol = 1e-6\n",
    "    epoch = 50\n",
    "    k_sigma = 0.827\n",
    "\n",
    "    while (evalcount < maxEvals and fmin > fstop + tol):\n",
    "        x = xmin + sigma * local_state.normal(size=n)\n",
    "        f_x = func(x.reshape(1, -1))\n",
    "        f_x = f_x.item() if hasattr(f_x, \"item\") else f_x\n",
    "        evalcount += 1\n",
    "        if f_x < fmin:\n",
    "            xmin = np.copy(x)\n",
    "            fmin = f_x\n",
    "            osuccess += 1\n",
    "\n",
    "        if (np.mod(evalcount, epoch) == 0):\n",
    "            ps = osuccess / epoch\n",
    "            if ps < 0.2:\n",
    "                sigma *= k_sigma\n",
    "            elif ps > 0.2:\n",
    "                sigma /= k_sigma\n",
    "            osuccess = 0\n",
    "            if evalcount % record_interval == 0:\n",
    "                fhistory.append(fmin)\n",
    "                shistory.append(sigma)\n",
    "\n",
    "        if evalcount % record_interval == 0:\n",
    "            fhistory.append(fmin)\n",
    "            shistory.append(sigma)\n",
    "\n",
    "    return xmin, fmin, fhistory, shistory\n",
    "\n",
    "def sample_discrete_laplace(lam):\n",
    "    \"\"\"\n",
    "    Samples an integer from a discrete Laplace distribution with parameter lam.\n",
    "    The PMF is: P(X=k) = ((1-lam)/(1+lam)) * lam**|k|  for k in Z.\n",
    "    \"\"\"\n",
    "    A = (1 - lam) / (1 + lam)\n",
    "    u = np.random.uniform()\n",
    "    if u < A:\n",
    "        return 0\n",
    "    else:\n",
    "        sign = 1 if np.random.uniform() < 0.5 else -1\n",
    "        # Geometric sampling gives a magnitude >= 1.\n",
    "        magnitude = np.random.geometric(p=(1 - lam))\n",
    "        return sign * magnitude\n",
    "\n",
    "def discrete_laplace_mutation(x, lb, ub, int_indices, lam=0.5):\n",
    "    \"\"\"\n",
    "    Applies a discrete Laplace mutation to the elements of x specified by int_indices.\n",
    "    Each mutated element is updated by adding a step sampled from the discrete Laplace distribution.\n",
    "    \"\"\"\n",
    "    x_new = np.copy(x)\n",
    "    for i in int_indices:\n",
    "        step = sample_discrete_laplace(lam)\n",
    "        x_new[i] = np.clip(x[i] + step, lb, ub)\n",
    "    return x_new\n",
    "\n",
    "def optimize_integer_part(xreal, lb, ub, n, max_evals, func, lam=0.5):\n",
    "    \"\"\"\n",
    "    Optimizes the integer part using discrete Laplace mutations.\n",
    "    If no improvement is observed for a number of iterations, a jump mutation (with an adjusted parameter)\n",
    "    is performed to help escape local minima.\n",
    "    \"\"\"\n",
    "    xint = np.round(xreal[n:]).astype(int)\n",
    "    candidate = np.concatenate([xreal[:n], xint]).reshape(1, -1)\n",
    "    best_fitness = func(candidate)\n",
    "    best_fitness = best_fitness.item() if hasattr(best_fitness, \"item\") else best_fitness\n",
    "    best_xint = xint.copy()\n",
    "\n",
    "    evalcount = 0\n",
    "    stuck_count = 0\n",
    "    stuck_threshold = 20  # If no improvement for 20 iterations, consider the search stuck.\n",
    "    jump_lam = lam       # Initial jump parameter for discrete Laplace.\n",
    "    k_down = 0.9         # Factor to decrease jump_lam if jump is successful.\n",
    "    k_up = 1.1           # Factor to increase jump_lam if jump is not successful.\n",
    "\n",
    "    while evalcount < max_evals:\n",
    "        mutated_xint = np.copy(xint)\n",
    "        for i in range(len(mutated_xint)):\n",
    "            if random.random() < 0.3:\n",
    "                mutated_xint = discrete_laplace_mutation(mutated_xint, lb, ub, [i], lam=lam)\n",
    "        candidate = np.concatenate([xreal[:n], mutated_xint]).reshape(1, -1)\n",
    "        fmutated = func(candidate)\n",
    "        fmutated = fmutated.item() if hasattr(fmutated, \"item\") else fmutated\n",
    "        evalcount += 1\n",
    "\n",
    "        if fmutated < best_fitness:\n",
    "            best_fitness = fmutated\n",
    "            best_xint = mutated_xint.copy()\n",
    "            xint = mutated_xint.copy()\n",
    "            stuck_count = 0\n",
    "        else:\n",
    "            stuck_count += 1\n",
    "\n",
    "        if stuck_count >= stuck_threshold:\n",
    "            # Perform a jump mutation on all integer variables using jump_lam.\n",
    "            jump_mutated = discrete_laplace_mutation(xint, lb, ub, list(range(len(xint))), lam=jump_lam)\n",
    "            candidate = np.concatenate([xreal[:n], jump_mutated]).reshape(1, -1)\n",
    "            new_fitness = func(candidate)\n",
    "            new_fitness = new_fitness.item() if hasattr(new_fitness, \"item\") else new_fitness\n",
    "            evalcount += 1\n",
    "\n",
    "            if new_fitness < best_fitness:\n",
    "                best_fitness = new_fitness\n",
    "                best_xint = jump_mutated.copy()\n",
    "                xint = jump_mutated.copy()\n",
    "                jump_lam = max(0.01, jump_lam * k_down)  # Decrease jump_lam for a finer jump next time.\n",
    "            else:\n",
    "                jump_lam = min(0.99, jump_lam * k_up)    # Increase jump_lam to try a larger jump.\n",
    "            stuck_count = 0  # Reset stuck counter.\n",
    "\n",
    "    return best_xint, best_fitness\n",
    "\n",
    "def optimize_real_part(func, lb, ub, dim, max_evals, record_interval=50):\n",
    "    xmin, fmin, fhistory, shistory = OnePlusOneEvolutionStrategy(dim, lb, ub, max_evals, func=func, record_interval=record_interval)\n",
    "    return xmin, fmin, fhistory, shistory\n",
    "\n",
    "def optimize_combined(func, lb, ub, dim, max_evals, record_interval=50, lam=0.5):\n",
    "    real_part, fmin_real, fhistory, shistory = optimize_real_part(func, lb, ub, dim, max_evals, record_interval=record_interval)\n",
    "    n = dim // 2\n",
    "    integer_part, fmin_integer = optimize_integer_part(real_part, lb, ub, n, max_evals, func=func, lam=lam)\n",
    "    optimized_solution = np.concatenate([real_part[:n], integer_part])\n",
    "    return optimized_solution, fmin_integer, fhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5226f853c999e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:21:29.575548Z",
     "start_time": "2025-02-17T11:16:29.692500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************genHcigar**************************\n",
      "genHcigar | Run 1: Best Combined Fitness = 0.0005801295628034118 | Best solution = [ 6.760599   -6.99979178  6.99984345 -7.0006944   6.99995456 -7.00004967\n",
      "  6.999903   -6.99994581  6.99944352 -7.00050263  6.99999377 -7.00099167\n",
      "  7.00129173 -6.99970381  6.99990159 -7.0006958   6.99998323 -7.00000774\n",
      "  7.00012174 -7.00005714  7.00033999 -7.0007071   6.99962004 -7.00007997\n",
      "  7.00031251 -7.00062883  6.99986745 -7.00031263  6.99921304 -6.99933715\n",
      "  6.99961113 -7.00018792  7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.        ]\n",
      "genHcigar | Run 2: Best Combined Fitness = 0.0001223582231321912 | Best solution = [ 6.89025152 -7.00007207  7.00004338 -7.00047934  6.99970401 -7.0004186\n",
      "  6.99992312 -7.00032791  7.00028308 -6.99966993  7.00008536 -6.9999244\n",
      "  6.99948435 -6.99994054  6.99990493 -6.99976701  7.00006667 -6.99975873\n",
      "  6.99998857 -7.00036166  7.0001594  -6.99965828  6.99975113 -6.99972776\n",
      "  7.0000276  -6.99994682  7.00005241 -6.999668    6.99959974 -6.99990552\n",
      "  7.00007368 -6.9999933   7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.        ]\n",
      "genHcigar | Run 3: Best Combined Fitness = 7.380206693755703e-07 | Best solution = [ 6.99146386 -6.9999821   6.99998486 -6.99999148  7.00001939 -6.99997715\n",
      "  6.99999113 -7.00000751  7.00002499 -7.00001659  7.00000241 -7.00000578\n",
      "  6.99998649 -7.00000099  7.00000417 -7.00002405  6.99999415 -6.99999226\n",
      "  6.9999701  -7.00001135  7.00001177 -7.00003773  6.99999143 -6.99995852\n",
      "  6.99997548 -6.99997698  7.00001266 -7.00000491  7.00000857 -7.00000549\n",
      "  6.99999196 -7.00000582  7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.          7.         -7.\n",
      "  7.         -7.          7.         -7.        ]\n"
     ]
    }
   ],
   "source": [
    "lb, ub = -100, 100\n",
    "dim = 64\n",
    "N = dim // 2\n",
    "setC(N)\n",
    "c = 100\n",
    "lamm = 0.3\n",
    "maxEvals = [80000, 100000, 500000]\n",
    "NRUNS = 30\n",
    "X = np.full((3 * NRUNS, dim + 2), np.nan)\n",
    "plt.figure(figsize=(12, 6))\n",
    "objFunc = \"MixedVarsEllipsoid\"\n",
    "\n",
    "for index, funcName in enumerate(['genHcigar', 'genRotatedHellipse', 'genHadamardHellipse']):\n",
    "#for index, funcName in enumerate(['genRotatedHellipse', 'genHadamardHellipse']):\n",
    "#for index, funcName in enumerate(['genHadamardHellipse']):\n",
    "    H = eval(f'Efunc.{funcName}')(dim, c)\n",
    "    f = eval(f'f_mixed.{objFunc}')(d=dim, bid=0, ind=N, H=H, c=c, max_eval=maxEvals[index])\n",
    "\n",
    "    function_histories = []  # To store fitness histories for averaging across runs.\n",
    "    print(f\"**************************{funcName}**************************\")\n",
    "    for k in range(NRUNS):\n",
    "        optimized_solution, fmin, fhistory = optimize_combined(func=f, lb=lb, ub=ub, dim=dim, max_evals=maxEvals[index], lam=lamm)\n",
    "        print(f\"{funcName} | Run {k + 1}: Best Combined Fitness = {fmin} | Best solution = {optimized_solution}\")\n",
    "        function_histories.append(fhistory)\n",
    "    print(f\"**************************{funcName}**************************\\n\")\n",
    "\n",
    "    max_length = max(len(history) for history in function_histories)\n",
    "    uniform_histories = np.array([\n",
    "        np.pad(history, (0, max_length - len(history)), mode='edge')\n",
    "        if len(history) < max_length else history[:max_length]\n",
    "        for history in function_histories\n",
    "    ])\n",
    "    function_histories = np.array(uniform_histories)\n",
    "    function_histories = np.squeeze(function_histories)\n",
    "    mean_fitness = np.mean(function_histories, axis=0)\n",
    "    std_fitness = np.std(function_histories, axis=0)\n",
    "\n",
    "    plt.plot(mean_fitness, label=f\"{funcName} (Mean Fitness)\", linewidth=2.5)\n",
    "    if function_histories.ndim != 2:\n",
    "        raise ValueError(f\"function_histories has incorrect shape: {function_histories.shape}\")\n",
    "    plt.fill_between(range(len(mean_fitness)), mean_fitness - std_fitness, mean_fitness + std_fitness, alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Average Best Fitness\")\n",
    "plt.title(\"Average Fitness History Across Runs\")\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1000)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), fontsize=9, frameon=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
